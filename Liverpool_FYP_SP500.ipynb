{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52be48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price              Open         High          Low        Close      Volume\n",
      "Date                                                                      \n",
      "2006-01-03  1248.290039  1270.219971  1245.739990  1268.800049  2554570000\n",
      "2006-01-04  1268.800049  1275.369995  1267.739990  1273.459961  2515330000\n",
      "2006-01-05  1273.459961  1276.910034  1270.300049  1273.479980  2433340000\n",
      "2006-01-06  1273.479980  1286.089966  1273.479980  1285.449951  2446560000\n",
      "2006-01-09  1285.449951  1290.780029  1284.819946  1290.150024  2301490000\n",
      "...                 ...          ...          ...          ...         ...\n",
      "2025-04-03  5492.740234  5499.529785  5390.830078  5396.520020  7210470000\n",
      "2025-04-04  5292.140137  5292.140137  5069.899902  5074.080078  8853500000\n",
      "2025-04-07  4953.790039  5246.569824  4835.040039  5062.250000  8691980000\n",
      "2025-04-08  5193.569824  5267.470215  4910.419922  4982.770020  7408140000\n",
      "2025-04-09  4965.279785  5481.339844  4948.430176  5456.899902  9489600000\n",
      "\n",
      "[4848 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sp500 = yf.download(\"^GSPC\", start=\"2006-01-01\", end=\"2025-04-10\")\n",
    "\n",
    "sp500 = sp500[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "sp500.columns = sp500.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "print(sp500)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8a4a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ta in ./anaconda3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.10/site-packages (from ta) (1.5.3)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.10/site-packages (from ta) (1.24.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.10/site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./anaconda3/lib/python3.10/site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->ta) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2347c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta  \n",
    "from ta.trend import MACD\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    required_cols = {'Close', 'High', 'Low'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        missing = required_cols - set(df.columns)\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    \n",
    "    macd_indicator = MACD(close=df['Close'])\n",
    "    df['MACD'] = macd_indicator.macd()\n",
    "    # df['MACD_signal'] = macd_indicator.macd_signal()\n",
    "    # df['MACD_diff'] = macd_indicator.macd_diff()\n",
    "\n",
    "    # RSI\n",
    "    df['RSI'] = ta.momentum.rsi(df['Close'])\n",
    "\n",
    "    # ATR\n",
    "    df['ATR'] = ta.volatility.average_true_range(df['High'], df['Low'], df['Close'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c0e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price              Open         High          Low        Close      Volume  \\\n",
      "Date                                                                         \n",
      "2006-01-03  1248.290039  1270.219971  1245.739990  1268.800049  2554570000   \n",
      "2006-01-04  1268.800049  1275.369995  1267.739990  1273.459961  2515330000   \n",
      "2006-01-05  1273.459961  1276.910034  1270.300049  1273.479980  2433340000   \n",
      "2006-01-06  1273.479980  1286.089966  1273.479980  1285.449951  2446560000   \n",
      "2006-01-09  1285.449951  1290.780029  1284.819946  1290.150024  2301490000   \n",
      "...                 ...          ...          ...          ...         ...   \n",
      "2025-04-03  5492.740234  5499.529785  5390.830078  5396.520020  7210470000   \n",
      "2025-04-04  5292.140137  5292.140137  5069.899902  5074.080078  8853500000   \n",
      "2025-04-07  4953.790039  5246.569824  4835.040039  5062.250000  8691980000   \n",
      "2025-04-08  5193.569824  5267.470215  4910.419922  4982.770020  7408140000   \n",
      "2025-04-09  4965.279785  5481.339844  4948.430176  5456.899902  9489600000   \n",
      "\n",
      "Price             MACD        RSI         ATR  \n",
      "Date                                           \n",
      "2006-01-03         NaN        NaN    0.000000  \n",
      "2006-01-04         NaN        NaN    0.000000  \n",
      "2006-01-05         NaN        NaN    0.000000  \n",
      "2006-01-06         NaN        NaN    0.000000  \n",
      "2006-01-09         NaN        NaN    0.000000  \n",
      "...                ...        ...         ...  \n",
      "2025-04-03  -76.488007  31.923661  109.403486  \n",
      "2025-04-04 -114.987527  23.250965  124.918960  \n",
      "2025-04-07 -144.784280  23.004037  145.391162  \n",
      "2025-04-08 -172.819634  21.362556  160.509671  \n",
      "2025-04-09 -154.992874  46.080099  187.109671  \n",
      "\n",
      "[4848 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "sp500 = add_technical_indicators(sp500)\n",
    "print(sp500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bac6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_datareader in ./anaconda3/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./anaconda3/lib/python3.10/site-packages (from pandas_datareader) (2.32.3)\n",
      "Requirement already satisfied: lxml in ./anaconda3/lib/python3.10/site-packages (from pandas_datareader) (4.9.1)\n",
      "Requirement already satisfied: pandas>=0.23 in ./anaconda3/lib/python3.10/site-packages (from pandas_datareader) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./anaconda3/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./anaconda3/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (1.24.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas_datareader) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_datareader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f711f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "def add_macro_indicators(df, start=\"2006-01-01\", end=\"2024-03-31\"):\n",
    "    import yfinance as yf\n",
    "    import pandas_datareader.data as web\n",
    "\n",
    "    vix = yf.download(\"^VIX\", start=start, end=end)[['Close']].rename(columns={\"Close\": \"VIX\"})\n",
    "    usdx = yf.download(\"DX-Y.NYB\", start=start, end=end)[['Close']].rename(columns={\"Close\": \"USDX\"})\n",
    "\n",
    "    effr = web.DataReader(\"EFFR\", \"fred\", start, end)\n",
    "    unrate = web.DataReader(\"UNRATE\", \"fred\", start, end)\n",
    "    umcsent = web.DataReader(\"UMCSENT\", \"fred\", start, end)\n",
    "\n",
    "    macro = vix.join([usdx, effr, unrate, umcsent])\n",
    "    macro = macro.fillna(method='ffill')\n",
    "\n",
    "    for col in macro.columns:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    df = df.join(macro)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd95f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close      Volume  \\\n",
      "Date                                                                         \n",
      "2006-01-03  1248.290039  1270.219971  1245.739990  1268.800049  2554570000   \n",
      "2006-01-04  1268.800049  1275.369995  1267.739990  1273.459961  2515330000   \n",
      "2006-01-05  1273.459961  1276.910034  1270.300049  1273.479980  2433340000   \n",
      "2006-01-06  1273.479980  1286.089966  1273.479980  1285.449951  2446560000   \n",
      "2006-01-09  1285.449951  1290.780029  1284.819946  1290.150024  2301490000   \n",
      "...                 ...          ...          ...          ...         ...   \n",
      "2025-04-03  5492.740234  5499.529785  5390.830078  5396.520020  7210470000   \n",
      "2025-04-04  5292.140137  5292.140137  5069.899902  5074.080078  8853500000   \n",
      "2025-04-07  4953.790039  5246.569824  4835.040039  5062.250000  8691980000   \n",
      "2025-04-08  5193.569824  5267.470215  4910.419922  4982.770020  7408140000   \n",
      "2025-04-09  4965.279785  5481.339844  4948.430176  5456.899902  9489600000   \n",
      "\n",
      "                  MACD        RSI         ATR  (VIX, ^VIX)  (USDX, DX-Y.NYB)  \\\n",
      "Date                                                                           \n",
      "2006-01-03         NaN        NaN    0.000000        11.14         89.839996   \n",
      "2006-01-04         NaN        NaN    0.000000        11.37         89.139999   \n",
      "2006-01-05         NaN        NaN    0.000000        11.31         89.330002   \n",
      "2006-01-06         NaN        NaN    0.000000        11.00         88.849998   \n",
      "2006-01-09         NaN        NaN    0.000000        11.13         89.250000   \n",
      "...                ...        ...         ...          ...               ...   \n",
      "2025-04-03  -76.488007  31.923661  109.403486          NaN               NaN   \n",
      "2025-04-04 -114.987527  23.250965  124.918960          NaN               NaN   \n",
      "2025-04-07 -144.784280  23.004037  145.391162          NaN               NaN   \n",
      "2025-04-08 -172.819634  21.362556  160.509671          NaN               NaN   \n",
      "2025-04-09 -154.992874  46.080099  187.109671          NaN               NaN   \n",
      "\n",
      "            EFFR  UNRATE  UMCSENT  \n",
      "Date                               \n",
      "2006-01-03  4.34     NaN      NaN  \n",
      "2006-01-04  4.22     NaN      NaN  \n",
      "2006-01-05  4.24     NaN      NaN  \n",
      "2006-01-06  4.22     NaN      NaN  \n",
      "2006-01-09  4.25     NaN      NaN  \n",
      "...          ...     ...      ...  \n",
      "2025-04-03   NaN     NaN      NaN  \n",
      "2025-04-04   NaN     NaN      NaN  \n",
      "2025-04-07   NaN     NaN      NaN  \n",
      "2025-04-08   NaN     NaN      NaN  \n",
      "2025-04-09   NaN     NaN      NaN  \n",
      "\n",
      "[4848 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "sp500 = add_macro_indicators(sp500)\n",
    "print(sp500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38307c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soft_labels(y_tensor, num_classes, sigma=0.7):\n",
    "    \n",
    "    soft_labels = []\n",
    "    for label in y_tensor:\n",
    "        distances = torch.arange(num_classes).float().to(label.device) - label.float()\n",
    "        weights = torch.exp(-0.5 * (distances / sigma) ** 2)\n",
    "        weights /= weights.sum()\n",
    "        soft_labels.append(weights)\n",
    "    return torch.stack(soft_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f49b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4445, 120, 13)\n",
      "y shape: (4445,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sp500.columns = [f'{col[0]}_{col[1]}' if isinstance(col, tuple) else col for col in sp500.columns]\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'MACD', 'RSI', 'ATR',\n",
    "    'EFFR', 'UNRATE', 'UMCSENT',\n",
    "    'VIX_^VIX', 'USDX_DX-Y.NYB'\n",
    "]\n",
    "\n",
    "\n",
    "sp500['log_return'] = np.log(sp500['Close'] / sp500['Close'].shift(1))\n",
    "\n",
    "\n",
    "## Classification 9 classes\n",
    "\n",
    "num_classes = 9\n",
    "\n",
    "\n",
    "sp500['return_class'], bin_edges = pd.qcut(\n",
    "    sp500['log_return'], \n",
    "    q=num_classes,           \n",
    "    labels=False,            \n",
    "    retbins=True,            \n",
    "    duplicates='drop'        \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## Cleaning \n",
    "def clean_and_prepare_data(df, feature_cols, label_col, window_size=120):\n",
    "    for col in feature_cols:\n",
    "        assert col in df.columns, f\"col not exist: {col}\"\n",
    "    assert label_col in df.columns, f\"label_col not exist: {label_col}\"\n",
    "\n",
    "    df_clean = df.dropna(subset=feature_cols + [label_col]).copy()\n",
    "\n",
    "    stds = df_clean[feature_cols].std()\n",
    "    zero_std_cols = stds[stds == 0].index.tolist()\n",
    "    if zero_std_cols:\n",
    "        print(f\"Remove because of zero {zero_std_cols}\")\n",
    "    feature_cols = [col for col in feature_cols if col not in zero_std_cols]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df_clean[feature_cols])\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(df_clean)):\n",
    "        X.append(scaled_features[i - window_size:i])\n",
    "        y.append(df_clean[label_col].iloc[i])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = clean_and_prepare_data(sp500, feature_cols, 'return_class', window_size=120)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7ab64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample in each class\n",
      "0.0    539\n",
      "1.0    538\n",
      "2.0    539\n",
      "3.0    538\n",
      "4.0    539\n",
      "5.0    538\n",
      "6.0    539\n",
      "7.0    538\n",
      "8.0    539\n",
      "Name: return_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class_counts = sp500['return_class'].value_counts().sort_index()\n",
    "print(\"Number of sample in each class\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a430f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3556, 120, 13)\n",
      "X_test shape: (889, 120, 13)\n",
      "y_train shape: (3556,)\n",
      "y_test shape: (889,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False  \n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b982e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "num_classes = 9\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39c6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleRNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleRNNClassifier, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  \n",
    "        out = out[:, -1, :]    \n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "class ESNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, reservoir_size, num_classes, spectral_radius=0.9, leaking_rate=0.15):\n",
    "        super().__init__()\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "\n",
    "        \n",
    "        self.input_weights = nn.Parameter(\n",
    "            torch.randn(input_dim, reservoir_size) * 0.3,\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        # bias\n",
    "        self.bias = nn.Parameter(torch.randn(reservoir_size) * 0.01, requires_grad=True)\n",
    "\n",
    "        # reservoir \n",
    "        W = torch.randn(reservoir_size, reservoir_size) / (reservoir_size ** 0.5)\n",
    "        eigvals = torch.linalg.eigvals(W).abs()\n",
    "        max_eig = eigvals.max().item()\n",
    "        W = (W / max_eig) * spectral_radius\n",
    "        self.reservoir_weights = nn.Parameter(W, requires_grad=False)\n",
    "\n",
    "        \n",
    "        self.readout = nn.Sequential(\n",
    "    nn.Linear(reservoir_size, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, num_classes)\n",
    ")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        states = torch.zeros(batch_size, self.reservoir_size, device=device)\n",
    "        all_states = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            u = x[:, t, :]  \n",
    "            preact = u @ self.input_weights + states @ self.reservoir_weights + self.bias\n",
    "            new_state = torch.tanh(preact)\n",
    "            states = (1 - self.leaking_rate) * states + self.leaking_rate * new_state\n",
    "            all_states.append(states.unsqueeze(1))  # shape: (batch, 1, reservoir)\n",
    "\n",
    "        all_states = torch.cat(all_states, dim=1)  # shape: (batch, seq_len, reservoir_size)\n",
    "        \n",
    "        pooled = all_states.mean(dim=1)\n",
    "        return self.readout(pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a36fcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = {\n",
    "    \"RNN\" : SimpleRNNClassifier(input_size=X.shape[2], hidden_size=64, num_classes=num_classes).to(device),\n",
    "    \"LSTM\": LSTMClassifier(input_size=X.shape[2], hidden_size=64, num_classes=num_classes).to(device),\n",
    "    \"ESN\":   ESNClassifier(input_dim=X.shape[2], reservoir_size=64, num_classes=num_classes, spectral_radius=0.95, leaking_rate=0.1).to(device)    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(num_classes),\n",
    "    y=y_train  \n",
    ")\n",
    "\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d45ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin edges: [-0.1276522  -0.01129563 -0.00519785 -0.00207425 -0.00018688  0.00159394\n",
      "  0.00374235  0.00658771  0.01135793  0.10957197]\n",
      "Class 0: from -0.1277 to -0.0113\n",
      "Class 1: from -0.0113 to -0.0052\n",
      "Class 2: from -0.0052 to -0.0021\n",
      "Class 3: from -0.0021 to -0.0002\n",
      "Class 4: from -0.0002 to 0.0016\n",
      "Class 5: from 0.0016 to 0.0037\n",
      "Class 6: from 0.0037 to 0.0066\n",
      "Class 7: from 0.0066 to 0.0114\n",
      "Class 8: from 0.0114 to 0.1096\n"
     ]
    }
   ],
   "source": [
    "sp500['return_class'].value_counts().sort_index()\n",
    "\n",
    "## Bin range \n",
    "\n",
    "print(\"Bin edges:\", bin_edges)\n",
    "\n",
    "\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    print(f\"Class {i}: from {bin_edges[i]:.4f} to {bin_edges[i+1]:.4f}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db7c02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, name, num_epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        acc = correct / total * 100\n",
    "        print(f\"[{name}] Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4000720",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model\n",
    "\n",
    "train_model(models[\"RNN\"], \"RNN\", num_epochs=150)\n",
    "train_model(models[\"LSTM\"], \"LSTM\", num_epochs=150)\n",
    "train_model(models[\"ESN\"], \"ESN\", num_epochs=150)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
